{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, csv, logging, re\n",
        "from datetime import datetime, timedelta\n",
        "from io import StringIO\n",
        "import pandas as pd, requests\n",
        "from tenacity import retry, stop_after_attempt, wait_fixed\n",
        "\n",
        "TARGET_DATE_STR = \"TODAY\"\n",
        "ALSO_FETCH_PREV = True\n",
        "\n",
        "try:\n",
        "    PROJECT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
        "except NameError:\n",
        "    PROJECT_DIR = os.getcwd()\n",
        "\n",
        "DATA_DIR = os.path.join(PROJECT_DIR, \"data\")\n",
        "RAW_DIR = os.path.join(DATA_DIR, \"raw\")\n",
        "CLEAN_DIR = os.path.join(DATA_DIR, \"clean\")\n",
        "os.makedirs(RAW_DIR, exist_ok=True)\n",
        "os.makedirs(CLEAN_DIR, exist_ok=True)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
        "\n",
        "def parse_target_date(s):\n",
        "    return datetime.today() if str(s).upper()==\"TODAY\" else datetime.strptime(s, \"%Y-%m-%d\")\n",
        "\n",
        "def previous_calendar_day(dt):\n",
        "    return dt - timedelta(days=1)\n",
        "\n",
        "REQUEST_HEADERS = {\n",
        "    \"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "                   \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "                   \"Chrome/120.0.0.0 Safari/537.36\"),\n",
        "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "    \"Connection\": \"keep-alive\",\n",
        "    \"Referer\": \"https://www.nseindia.com/all-reports\",\n",
        "}\n",
        "\n",
        "def mto_urls_for_date(dt):\n",
        "    ddmmyyyy = dt.strftime(\"%d%m%Y\")\n",
        "    f = f\"MTO_{ddmmyyyy}.DAT\"\n",
        "    return [\n",
        "        f\"https://archives.nseindia.com/archives/equities/mto/{f}\",\n",
        "        f\"https://nsearchives.nseindia.com/archives/equities/mto/{f}\",\n",
        "        f\"https://www1.nseindia.com/archives/equities/mto/{f}\",\n",
        "    ]\n",
        "\n",
        "def looks_like_html(text):\n",
        "    t = text.lstrip()\n",
        "    return t.startswith(\"<\") or \"<!DOCTYPE\" in t or \"Access Denied\" in t or \"Denied\" in t\n",
        "\n",
        "def shorten(text, n=300):\n",
        "    s = text.replace(\"\\r\", \" \")[:n]\n",
        "    return re.sub(r\"\\s+\", \" \", s)\n",
        "\n",
        "@retry(stop=stop_after_attempt(4), wait=wait_fixed(1))\n",
        "def download_mto_text(dt):\n",
        "    s = requests.Session()\n",
        "    s.headers.update(REQUEST_HEADERS)\n",
        "    try: s.get(\"https://www.nseindia.com\", timeout=15)\n",
        "    except Exception: pass\n",
        "    last_error = None\n",
        "    for url in mto_urls_for_date(dt):\n",
        "        try:\n",
        "            logging.info(f\"Fetching {url}\")\n",
        "            r = s.get(url, timeout=25)\n",
        "            if r.status_code != 200:\n",
        "                last_error = Exception(f\"HTTP {r.status_code} from {url}\")\n",
        "                continue\n",
        "            text = r.text\n",
        "            if looks_like_html(text):\n",
        "                logging.warning(f\"HTML/error from {url}: {shorten(text)}\")\n",
        "                last_error = Exception(\"Received HTML/error instead of .DAT\")\n",
        "                continue\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            logging.warning(f\"Fetch failed from {url}: {e}\")\n",
        "            last_error = e\n",
        "    if last_error: raise last_error\n",
        "    raise RuntimeError(\"All archive mirrors failed.\")\n",
        "\n",
        "def parse_mto_text_to_frame(raw_text):\n",
        "    lines = [ln.strip() for ln in raw_text.splitlines() if ln.strip()]\n",
        "    header_index = -1\n",
        "    for i, ln in enumerate(lines):\n",
        "        low = ln.lower()\n",
        "        if (\"symbol\" in low and \"series\" in low and \",\" in ln) or (\"record type\" in low and \"name of security\" in low and \",\" in ln):\n",
        "            header_index = i\n",
        "            break\n",
        "    if header_index == -1:\n",
        "        raise ValueError(\"Could not find header. \" + shorten(raw_text, 500))\n",
        "    table_lines = [lines[header_index]]\n",
        "    for ln in lines[header_index + 1:]:\n",
        "        low = ln.lower()\n",
        "        if low.startswith(\"total\") or low.startswith(\"grand total\"): break\n",
        "        if \",\" in ln: table_lines.append(ln)\n",
        "    rows = list(csv.reader(StringIO(\"\\n\".join(table_lines))))\n",
        "    if not rows or len(rows) < 2: raise ValueError(\"No data rows detected.\")\n",
        "    header_raw, data_rows = rows[0], rows[1:]\n",
        "    header_norm = [h.strip().upper().replace(\" \", \"_\").replace(\"%\", \"PCT\") for h in header_raw]\n",
        "    if (\"NAME_OF_SECURITY\" in header_norm) and (\"SERIES\" not in header_norm):\n",
        "        first_len = len(data_rows[0]); header_len = len(header_norm)\n",
        "        if first_len == header_len + 1:\n",
        "            try: insert_at = header_norm.index(\"NAME_OF_SECURITY\") + 1\n",
        "            except ValueError: insert_at = 3\n",
        "            header_norm = header_norm[:insert_at] + [\"SERIES\"] + header_norm[insert_at:]\n",
        "            fixed = []\n",
        "            for r in data_rows:\n",
        "                if len(r) == header_len: r = r[:insert_at] + [\"\"] + r[insert_at:]\n",
        "                fixed.append(r)\n",
        "            data_rows = fixed\n",
        "    df = pd.DataFrame(data_rows, columns=header_norm)\n",
        "    def pick(cands):\n",
        "        for c in cands:\n",
        "            if c in df.columns: return c\n",
        "        raise KeyError(f\"Missing {cands}. Got {list(df.columns)}\")\n",
        "    col_symbol = \"SYMBOL\" if \"SYMBOL\" in df.columns else pick([\"NAME_OF_SECURITY\"])\n",
        "    col_series = pick([\"SERIES\"])\n",
        "    col_qty = pick([\"QTY_TRADED\",\"QTY_TRADED_(NOS)\",\"QTY_TRADED_NOS\",\"QUANTITY_TRADED\"])\n",
        "    col_deliv = pick([\"DELIVERABLE_QTY\",\"DELIVERABLE_QTY_(NOS)\",\"DELIVERABLE_QTY_NOS\",\n",
        "                      \"DELIVERABLE_QUANTITY(GROSS_ACROSS_CLIENT_LEVEL)\".upper(),\n",
        "                      \"DELIVERABLE_QUANTITY(GROSS_ACROSS_CLIENT_LEVEL)\".replace(\" \",\"_\").upper()])\n",
        "    col_deliv_pct = None\n",
        "    for c in df.columns:\n",
        "        if \"DELIVERABLE\" in c and \"TRADED\" in c and \"PCT\" in c: col_deliv_pct = c; break\n",
        "    if not col_deliv_pct:\n",
        "        for c in df.columns:\n",
        "            if \"DLY\" in c and \"PCT\" in c: col_deliv_pct = c; break\n",
        "    if not col_deliv_pct:\n",
        "        for c in df.columns:\n",
        "            if c.endswith(\"PCT\"): col_deliv_pct = c; break\n",
        "    if not col_deliv_pct:\n",
        "        for c in df.columns:\n",
        "            if \"DELIVERABLE\" in c and \"TRADED\" in c and (\"TO_TRADED_QUANTITY\" in c or \"TO_TRADED_QTY\" in c): col_deliv_pct = c; break\n",
        "    if not col_deliv_pct: raise KeyError(\"Deliverable % column not found.\")\n",
        "    out = df[[col_symbol, col_series, col_qty, col_deliv, col_deliv_pct]].copy()\n",
        "    out.columns = [\"SYMBOL\", \"SERIES\", \"QTY_TRADED\", \"DELIV_QTY\", \"DELIV_PCT\"]\n",
        "    def to_num(x):\n",
        "        x = (x or \"\").replace(\",\", \"\").replace(\"%\", \"\").strip()\n",
        "        if x in (\"\", \"-\", \"NA\"): return None\n",
        "        try: return float(x)\n",
        "        except: return None\n",
        "    out[\"QTY_TRADED\"] = out[\"QTY_TRADED\"].map(to_num)\n",
        "    out[\"DELIV_QTY\"] = out[\"DELIV_QTY\"].map(to_num)\n",
        "    out[\"DELIV_PCT\"] = out[\"DELIV_PCT\"].map(to_num)\n",
        "    out[\"SYMBOL\"] = out[\"SYMBOL\"].astype(str).str.strip()\n",
        "    out[\"SERIES\"] = out[\"SERIES\"].astype(str).str.strip()\n",
        "    out = out[out[\"SYMBOL\"].str.len() > 0].reset_index(drop=True)\n",
        "    return out\n",
        "\n",
        "def write_raw(dt, text):\n",
        "    p = os.path.join(RAW_DIR, f\"MTO_{dt.strftime('%Y-%m-%d')}.DAT\")\n",
        "    open(p, \"w\", encoding=\"utf-8\").write(text)\n",
        "    return p\n",
        "\n",
        "def write_clean_csv(dt, df):\n",
        "    p = os.path.join(CLEAN_DIR, f\"delivery_{dt.strftime('%Y-%m-%d')}.csv\")\n",
        "    df.to_csv(p, index=False)\n",
        "    return p\n",
        "\n",
        "def fetch_and_clean_for_date(dt):\n",
        "    text = download_mto_text(dt)\n",
        "    write_raw(dt, text)\n",
        "    df = parse_mto_text_to_frame(text)\n",
        "    path = write_clean_csv(dt, df)\n",
        "    logging.info(f\"Saved clean CSV: {path}\")\n",
        "    return path\n",
        "\n",
        "target_dt = parse_target_date(TARGET_DATE_STR)\n",
        "fetch_and_clean_for_date(target_dt)\n",
        "if ALSO_FETCH_PREV:\n",
        "    fetch_and_clean_for_date(previous_calendar_day(target_dt))\n"
      ],
      "metadata": {
        "id": "WyKb12ASmb5f"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, logging\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "\n",
        "TARGET_DATE_STR = \"TODAY\"\n",
        "\n",
        "try:\n",
        "    PROJECT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
        "except NameError:\n",
        "    PROJECT_DIR = os.getcwd()\n",
        "\n",
        "CLEAN_DIR = os.path.join(PROJECT_DIR, \"data\", \"clean\")\n",
        "OUT_DIR = os.path.join(PROJECT_DIR, \"data\", \"output\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
        "\n",
        "def parse_target_date(s):\n",
        "    return datetime.today() if str(s).upper()==\"TODAY\" else datetime.strptime(s, \"%Y-%m-%d\")\n",
        "\n",
        "def previous_calendar_day(dt):\n",
        "    return dt - timedelta(days=1)\n",
        "\n",
        "def path_for(date_obj):\n",
        "    return os.path.join(CLEAN_DIR, f\"delivery_{date_obj.strftime('%Y-%m-%d')}.csv\")\n",
        "\n",
        "def main():\n",
        "    dt_today = parse_target_date(TARGET_DATE_STR)\n",
        "    dt_prev = previous_calendar_day(dt_today)\n",
        "    p_today = path_for(dt_today)\n",
        "    p_prev = path_for(dt_prev)\n",
        "    if not os.path.exists(p_today): raise FileNotFoundError(f\"Missing {p_today}\")\n",
        "    if not os.path.exists(p_prev): raise FileNotFoundError(f\"Missing {p_prev}\")\n",
        "    df_today = pd.read_csv(p_today)\n",
        "    df_prev = pd.read_csv(p_prev)\n",
        "    df_today = df_today[df_today[\"SERIES\"]==\"EQ\"][[\"SYMBOL\",\"DELIV_PCT\"]].rename(columns={\"DELIV_PCT\":\"today_deliv_pct\"})\n",
        "    df_prev = df_prev[df_prev[\"SERIES\"]==\"EQ\"][[\"SYMBOL\",\"DELIV_PCT\"]].rename(columns={\"DELIV_PCT\":\"prev_deliv_pct\"})\n",
        "    merged = df_today.merge(df_prev, on=\"SYMBOL\", how=\"inner\")\n",
        "    merged[\"change_deliv_pct\"] = merged[\"today_deliv_pct\"] - merged[\"prev_deliv_pct\"]\n",
        "    top10 = merged.sort_values(\"change_deliv_pct\", ascending=False).head(10).copy()\n",
        "    top10[\"date_today\"] = dt_today.strftime(\"%Y-%m-%d\")\n",
        "    top10[\"date_prev\"] = dt_prev.strftime(\"%Y-%m-%d\")\n",
        "    cols = [\"SYMBOL\",\"today_deliv_pct\",\"prev_deliv_pct\",\"change_deliv_pct\",\"date_today\",\"date_prev\"]\n",
        "    top10 = top10[cols]\n",
        "    out_path = os.path.join(OUT_DIR, f\"top10_{dt_today.strftime('%Y-%m-%d')}.csv\")\n",
        "    top10.to_csv(out_path, index=False)\n",
        "    disp = top10.copy()\n",
        "    for c in [\"today_deliv_pct\",\"prev_deliv_pct\",\"change_deliv_pct\"]:\n",
        "        disp[c] = disp[c].map(lambda x: f\"{x:.2f}\" if pd.notnull(x) else \"\")\n",
        "    print(\"Top 10 increase in delivery percentage (largest first)\")\n",
        "    print(\"Date:\", dt_today.strftime(\"%Y-%m-%d\"))\n",
        "    print(disp.to_string(index=False))\n",
        "    print(\"\\nSaved CSV:\", out_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "UsPERJr_nD3k",
        "outputId": "0fc9669a-8787-4191-c33b-4567ea0a4946",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 increase in delivery percentage (largest first)\n",
            "Date: 2025-10-31\n",
            "    SYMBOL today_deliv_pct prev_deliv_pct change_deliv_pct date_today  date_prev\n",
            "  ARENTERP           88.90          23.91            64.99 2025-10-31 2025-10-30\n",
            " SENSEXADD           91.93          29.60            62.33 2025-10-31 2025-10-30\n",
            "      ISFT           84.86          27.56            57.30 2025-10-31 2025-10-30\n",
            "   PANSARI           96.28          43.38            52.90 2025-10-31 2025-10-30\n",
            "  NIFITETF           69.21          17.59            51.62 2025-10-31 2025-10-30\n",
            "      WIPL           65.88          14.45            51.43 2025-10-31 2025-10-30\n",
            "CENTURYPLY           80.95          30.42            50.53 2025-10-31 2025-10-30\n",
            "      ICRA           92.92          44.15            48.77 2025-10-31 2025-10-30\n",
            "GROWWLOVOL           88.01          39.33            48.68 2025-10-31 2025-10-30\n",
            "      DBOL           74.58          26.69            47.89 2025-10-31 2025-10-30\n",
            "\n",
            "Saved CSV: /content/data/output/top10_2025-10-31.csv\n"
          ]
        }
      ]
    }
  ]
}